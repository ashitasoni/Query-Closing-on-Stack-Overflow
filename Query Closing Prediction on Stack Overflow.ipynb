{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features for classifiers\n",
    "(&)in data (+) calculate\n",
    "\n",
    "#### Query Content:  \n",
    "&Date of creation of post-User account creation date  \n",
    "+Count of lowercase chars in body  \n",
    "+Count of uppercase chars in body  \n",
    "+lowercase to uppercase ratio in body  \n",
    "+character count in body  (removed)  \n",
    "+word count in body  \n",
    "+code length in body  \n",
    "+length of first line in body   \n",
    "+punctuations count  \n",
    "+sentence count in body  \n",
    "+count of sentences starting with you  \n",
    "+count of sentences starting with i  \n",
    "+count of interrogative words  \n",
    "+count of URLs in body  \n",
    "+count of stackoverflow URLs in body  \n",
    "+count of short words in body  \n",
    "+count of tags  \n",
    "+tags weight(to be worked upon)  \n",
    "\n",
    "+character count in title  \n",
    "+word count in title     \n",
    "+title starting with what/which/how (useful for opinion based questions) or use interrogative words check\n",
    "\n",
    "\n",
    "#### User profile\n",
    "\n",
    "&Reputation  \n",
    "&View count  \n",
    "&upvotes received  \n",
    "&downvotes received  \n",
    "user Badges  \n",
    "&about me filled  \n",
    "&website url filled  \n",
    "&location filled  \n",
    "&profile image url filled    \n",
    "questions asked by user  \n",
    "answers posted by user  \n",
    "CloseVotesReceived: The number of close votes received by the user for his posts  \n",
    "Previous Questions with -ve score  \n",
    "Previous Questions with +ve score  \n",
    "Previous Questions with 0 score  \n",
    "Previous Answers with -ve score  \n",
    "Previous Answers with +ve score  \n",
    "Previous Answers with 0 score  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### URL count\n",
    "https://codeblog.jonskeet.uk/2010/08/29/writing-the-perfect-question/\n",
    "Often there will be other people in a similar situation, but the answers didn’t quite match your situation. Just like the above point about unusual constraints, it saves time if you can point out differences between your situation and other common ones. It’s even worth referring to other related questions explicitly – particularly if they’re on the same forum. Aside from anything else, this shows a certain amount of “due diligence” – people are generally more willing to help you if can show you’ve already put some effort in.  \n",
    "\n",
    "Sharing your research helps everyone. Tell us what you found and why it didn’t meet your needs. This demonstrates that you’ve taken the time to try to help yourself, it saves us from reiterating obvious answers, and above all, it helps you get a more specific and relevant answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Title length\n",
    "Write a title that summarizes the specific problem\n",
    "At the same time a “question” title of “Please help” is unlikely to do well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of interrogative words\n",
    "Make sure it’s obvious what you’re trying to get out of the question. Too many “questions” are actually just statements: when I do X, something goes wrong. Well, what did you expect it to do? What are you trying to accomplish? What have you already tried? What happened in those attempts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code length\n",
    "Shows effort done on the part of asker.  \n",
    "BUT  \n",
    "Be as short as possible. If I have to wade through hundreds of lines of code to find the problem, I’m doing work that you should be doing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### length of first sentence\n",
    "There’s no need to include greetings and sign-offs such as “Hi everyone!” and “Thanks – hope to get an answer soon” in the question. These will often be edited out by other users, as they’re basically a distraction. Greetings at the start of a question are particularly useless as they can take up valuable space in the snippet displayed in the question list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### some closing weight for tags such as homework?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resources for text cleaning: \n",
    "#https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
    "#https://github.com/SudalaiRajkumar/NLP/blob/master/src/Text%20Cleaning.ipynb\n",
    "#https://docs.python.org/3/library/re.html\n",
    "\n",
    "#Returns number of lowercase chars in the text\n",
    "def lowercaseCount(text):\n",
    "    lowercount=0\n",
    "    for w in text:\n",
    "        for char in w:\n",
    "            if(char.islower()):\n",
    "                lowercount+=1\n",
    "    return lowercount\n",
    "\n",
    "#Returns number of uppercase chars in the text\n",
    "def uppercaseCount(text):\n",
    "    uppercount=0\n",
    "    for w in text:\n",
    "        for char in w:\n",
    "            if(char.isupper()):\n",
    "                uppercount+=1\n",
    "    return uppercount\n",
    "    \n",
    "#Sentence tokenization\n",
    "from nltk import sent_tokenize\n",
    "#Tokenizes sentences into sentence list\n",
    "def getSentTokens(sentences):\n",
    "    return sent_tokenize(sentences)\n",
    "\n",
    "#Word tokenization\n",
    "from nltk import word_tokenize\n",
    "#Tokenizes sentence 1D list into words 2D list\n",
    "def getWordTokens(sentenceList):\n",
    "    return [word_tokenize(s) for s in sentenceList]\n",
    "\n",
    "#Punctuations removal\n",
    "def removePunctuations(word):\n",
    "    return re.sub(r'\\W+', '', word)\n",
    "\n",
    "#Stop words removal from list of words\n",
    "from nltk.corpus import stopwords\n",
    "eng_stop=set(stopwords.words('english'))\n",
    "#print(eng_stop)\n",
    "def removeStopwords(text):\n",
    "    return [word for word in text if word not in eng_stop]\n",
    "\n",
    "def sentencesStartWithYouCount(tokens):\n",
    "    count=0\n",
    "    for sentence in tokens:\n",
    "        if(sentence[0]==\"you\"):\n",
    "            #print(s)\n",
    "            count=count+1\n",
    "    return count;\n",
    "\n",
    "def sentencesStartWithICount(tokens):\n",
    "    count=0\n",
    "    for sentence in tokens:\n",
    "        if(sentence[0]==\"i\"):\n",
    "            #print(s)\n",
    "            count=count+1\n",
    "    return count;\n",
    "\n",
    "#https://stackoverflow.com/questions/6883049/regex-to-extract-urls-from-href-attribute-in-html-with-python\n",
    "#https://stackoverflow.com/questions/1374457/find-out-how-many-times-a-regex-matches-in-a-string-in-python\n",
    "#Returns count of url in a given post\n",
    "def urlCount(text):\n",
    "    urls=re.findall(r'https://?|ftp://',text)\n",
    "    print(urls)\n",
    "    return len(urls)\n",
    "\n",
    "#Returns count of URls pointing to Stack Overflow \n",
    "def SOUrlCount(text):\n",
    "    SOUrls=re.findall(r'https://stackoverflow.com',text)\n",
    "    print(SOUrls)\n",
    "    return len(SOUrls)\n",
    "    \n",
    "#Returns the length of total code present in the post\n",
    "def codeLength(text):\n",
    "    codes=re.findall(r\"<code>(.*?)</code>\",text,flags= re.DOTALL)\n",
    "    print(codes)\n",
    "    return len(''.join(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase count:103\n",
      "Uppercase count:7\n",
      "Lowercase chars to Upper chars ratio:14.714285714285714\n",
      "this's is@ 9 short, sentence. amazing! i have tried an approach. i am trying this. i'm trying. you should suggest some, too. you've done this before?\n"
     ]
    }
   ],
   "source": [
    "text = (\"This's is@ 9 short, sentence. Amazing! I have tried an approach. I am trying this. I'm trying. \" \n",
    "       \"You should suggest some, too. You've done this before?\")\n",
    "print(\"Lowercase count:\"+str(lowercaseCount(text)))\n",
    "print(\"Uppercase count:\"+str(uppercaseCount(text)))\n",
    "print(\"Lowercase chars to Upper chars ratio:\"+str( lowercaseCount(text)/uppercaseCount(text) ))\n",
    "text=text.lower()\n",
    "print(text);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://', 'https://', 'https://']\n",
      "3\n",
      "['https://stackoverflow.com']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "text2=(\"<p>Are there any free web based service to manage/use your remote computers?</p> \"\n",
    "\"<p>I use <a href=\\\"https://secure.logmein.com/home.asp\\\" rel=\\\"nofollow noreferrer\\\">Logmein</a> free. \"\n",
    "\"It solves the purpose. But wondering any other free services available.</p> \"\n",
    "\"<p>Heard <a href=\\\"https://www.copilot.com/\\\" rel=\\\"nofollow noreferrer\\\">Copilot</a> is great but not free!\"\n",
    "       \"<a href=\\\"https://stackoverflow.com/questions/51884419/how-to-paginate-stack-exchange-data-explorer-sede-results\\\" \"\n",
    "      )\n",
    "print(urlCount(text2))\n",
    "print(SOUrlCount(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' something here ', 'helloworld']\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "text3=(\"some text <code> something here </code> some text <code>hello\"\n",
    "\"world</code>\")\n",
    "print(codeLength(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence count:7\n",
      "[\"this's is@ 9 short, sentence.\", 'amazing!', 'i have tried an approach.', 'i am trying this.', \"i'm trying.\", 'you should suggest some, too.', \"you've done this before?\"]\n"
     ]
    }
   ],
   "source": [
    "sentences=getSentTokens(text)\n",
    "print(\"Sentence count:\"+str(len(sentences)))\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', \"'s\", 'is', '@', '9', 'short', ',', 'sentence', '.']\n",
      "['amazing', '!']\n",
      "['i', 'have', 'tried', 'an', 'approach', '.']\n",
      "['i', 'am', 'trying', 'this', '.']\n",
      "['i', \"'m\", 'trying', '.']\n",
      "['you', 'should', 'suggest', 'some', ',', 'too', '.']\n",
      "['you', \"'ve\", 'done', 'this', 'before', '?']\n"
     ]
    }
   ],
   "source": [
    "tokens=getWordTokens(sentences)\n",
    "#tokens is 2D list\n",
    "for sentence in tokens:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences starting with you:2\n",
      "Number of sentences starting with i:3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sentences starting with you:\"+str(sentencesStartWithYouCount(tokens)))\n",
    "print(\"Number of sentences starting with i:\"+str(sentencesStartWithICount(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 's', 'is', '9', 'short', 'sentence', 'amazing', 'i', 'have', 'tried', 'an', 'approach', 'i', 'am', 'trying', 'this', 'i', 'm', 'trying', 'you', 'should', 'suggest', 'some', 'too', 'you', 've', 'done', 'this', 'before']\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "tokens=[removePunctuations(w) for s in tokens for w in s]\n",
    "tokens=list( filter(None,tokens) )\n",
    "print(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9', 'short', 'sentence', 'amazing', 'tried', 'approach', 'trying', 'trying', 'suggest', 'done']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "tokens=removeStopwords(tokens)\n",
    "print(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If HistoryClosedDate is not null and ClosedDate is null\n",
    "then the post might be protected\n",
    "PostId=151969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple rows for same PostId=101754 in Off topic closed question database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
